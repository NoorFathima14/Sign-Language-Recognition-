{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1535339,"sourceType":"datasetVersion","datasetId":905361}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Define the path to the dataset\ntrain_folder = '/kaggle/input/indian-sign-language-dataset/data'\n\n# Step 1: Data Exploration and Visualization\n# Get the list of classes (labels) from the subfolders\nclass_names = sorted(os.listdir(train_folder))  # Sorted to maintain order\n\n# Display some images from each class in the dataset\nnum_images_to_display = 5  # Number of images to display for visualization\n\nplt.figure(figsize=(15, 5))\nfor i, class_name in enumerate(class_names[:num_images_to_display]):\n    class_folder = os.path.join(train_folder, class_name)\n    image_files = os.listdir(class_folder)\n\n    if image_files:\n        image_path = os.path.join(class_folder, image_files[0])\n        image = Image.open(image_path)\n        plt.subplot(1, num_images_to_display, i + 1)\n        plt.imshow(image)\n        plt.axis('off')\n        plt.title(class_name)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:07:13.894084Z","iopub.execute_input":"2024-10-30T15:07:13.894490Z","iopub.status.idle":"2024-10-30T15:07:15.452151Z","shell.execute_reply.started":"2024-10-30T15:07:13.894448Z","shell.execute_reply":"2024-10-30T15:07:15.451200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images_and_labels_with_augmentation(data_folder):\n    images, labels = [], []\n    for label in os.listdir(data_folder):\n        label_folder = os.path.join(data_folder, label)\n        for image_file in os.listdir(label_folder):\n            image_path = os.path.join(label_folder, image_file)\n            \n            # Load the image\n            image = cv2.imread(image_path)\n            \n            # Original Image\n            if image is not None:\n                # Ensure the original image is processed correctly\n                preprocessed_image = preprocess_image(image)\n                images.append(preprocessed_image)\n                labels.append(label)\n                \n                # Data Augmentation: Resize\n                resized_image = cv2.resize(image, (64, 64))\n                images.append(preprocess_image(resized_image))  # Ensure consistency\n                labels.append(label)\n                \n                # Data Augmentation: Crop\n                cropped_image = crop_image(image, (0, 0, 64, 64))  # Adjust coordinates as needed\n                images.append(preprocess_image(cropped_image))  # Ensure consistency\n                labels.append(label)\n\n                # Data Augmentation: Grayscale Conversion\n                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n                gray_image = cv2.resize(gray_image, (64, 64))\n                gray_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)  # Convert to 3 channels\n                images.append(gray_image)  # Ensure consistency\n                labels.append(label)\n\n                # Data Augmentation: Add Noise\n                noisy_image = add_noise(image)\n                noisy_image = preprocess_image(noisy_image)  # Ensure consistency\n                images.append(noisy_image)\n                labels.append(label)\n\n    return np.array(images), np.array(labels)\n\n# Function to preprocess images (resize to consistent shape)\ndef preprocess_image(image):\n    # Resize image to (64, 64, 3) for color images\n    if len(image.shape) == 3:\n        return cv2.resize(image, (64, 64))\n    # Resize grayscale image to (64, 64, 3) by converting\n    elif len(image.shape) == 2:  \n        return cv2.cvtColor(cv2.resize(image, (64, 64)), cv2.COLOR_GRAY2BGR)\n    return image\n\n# Function to crop the image (defining a rectangular region)\ndef crop_image(image, roi):\n    x1, y1, x2, y2 = roi\n    return image[y1:y2, x1:x2]\n\n# Function to add Gaussian noise to an image\ndef add_noise(image):\n    noise = np.random.normal(0, 25, image.shape).astype(np.uint8)  # Mean=0, Stddev=25\n    noisy_image = cv2.add(image, noise)\n    return noisy_image\n\n# Load images and labels with augmentation\nimages, labels = load_images_and_labels_with_augmentation(train_folder)\nprint(\"Done\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:07:15.453622Z","iopub.execute_input":"2024-10-30T15:07:15.454267Z","iopub.status.idle":"2024-10-30T15:11:30.911725Z","shell.execute_reply.started":"2024-10-30T15:07:15.454220Z","shell.execute_reply":"2024-10-30T15:11:30.910734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.feature import hog\n\nHOG_PARAMS = {\n    'orientations': 9,\n    'pixels_per_cell': (8, 8),\n    'cells_per_block': (2, 2),\n    'block_norm': 'L2-Hys'\n}\n\ndef extract_hog_features(images, hog_params):\n    hog_features = []\n    for image in images:\n        # Convert image to grayscale if it's not already\n        if len(image.shape) == 3:  # Check if the image is color\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        \n        hog_feature = hog(image, **hog_params)\n        hog_features.append(hog_feature)\n    return np.array(hog_features)\n\nhog_features = extract_hog_features(images, HOG_PARAMS)\n\nprint(\"HOG feature extraction completed!\")\nprint(\"HOG features shape:\", hog_features.shape)\nprint(\"Done\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:11:30.914075Z","iopub.execute_input":"2024-10-30T15:11:30.914391Z","iopub.status.idle":"2024-10-30T15:18:41.260196Z","shell.execute_reply.started":"2024-10-30T15:11:30.914357Z","shell.execute_reply":"2024-10-30T15:18:41.259218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 4: Split the Dataset\nX_train, X_test, y_train, y_test = train_test_split(hog_features, labels, test_size=0.2, random_state=42)\n\n# Step 5: Scale Features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nprint(\"Done\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:18:41.261279Z","iopub.execute_input":"2024-10-30T15:18:41.261727Z","iopub.status.idle":"2024-10-30T15:18:46.338764Z","shell.execute_reply.started":"2024-10-30T15:18:41.261685Z","shell.execute_reply":"2024-10-30T15:18:46.337747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 6: Train SVM Classifier\nsvm = SVC(C=0.1, kernel='linear')\nsvm.fit(X_train, y_train)\n\nprint(\"Done\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:18:46.340150Z","iopub.execute_input":"2024-10-30T15:18:46.340438Z","iopub.status.idle":"2024-10-30T15:51:52.531123Z","shell.execute_reply.started":"2024-10-30T15:18:46.340407Z","shell.execute_reply":"2024-10-30T15:51:52.529835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 6: Train KNN Classifier with best parameters\nknn = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='euclidean')\nknn.fit(X_train, y_train)\n\nprint(\"Done\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:51:52.532505Z","iopub.execute_input":"2024-10-30T15:51:52.532905Z","iopub.status.idle":"2024-10-30T15:51:52.765791Z","shell.execute_reply.started":"2024-10-30T15:51:52.532869Z","shell.execute_reply":"2024-10-30T15:51:52.764801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 7: Evaluate Model\ny_pred = svm.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(f\"SVM Model Accuracy: {accuracy:.2f}\")\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T15:51:52.766869Z","iopub.execute_input":"2024-10-30T15:51:52.767170Z","iopub.status.idle":"2024-10-30T16:18:00.908591Z","shell.execute_reply.started":"2024-10-30T15:51:52.767137Z","shell.execute_reply":"2024-10-30T16:18:00.907649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(f\"KNN Model Accuracy: {accuracy:.2f}\")\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T16:18:00.909806Z","iopub.execute_input":"2024-10-30T16:18:00.910101Z","iopub.status.idle":"2024-10-30T16:22:15.144393Z","shell.execute_reply.started":"2024-10-30T16:18:00.910068Z","shell.execute_reply":"2024-10-30T16:22:15.143477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optional: Save the Model and Scaler\nimport joblib\njoblib.dump(svm, '/kaggle/working/svm_model.pkl')\njoblib.dump(knn, '/kaggle/working/knn_model.pkl')\njoblib.dump(scaler, '/kaggle/working/scaler.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T16:22:15.147427Z","iopub.execute_input":"2024-10-30T16:22:15.147732Z","iopub.status.idle":"2024-10-30T16:22:17.894748Z","shell.execute_reply.started":"2024-10-30T16:22:15.147695Z","shell.execute_reply":"2024-10-30T16:22:17.893812Z"},"trusted":true},"execution_count":null,"outputs":[]}]}